/**
 * Serveur Backend pour l'interface Ollama
 * 
 * Ce serveur agit comme proxy entre le frontend et l'API Ollama locale.
 * Il gÃ¨re les problÃ¨mes de CORS et centralise la logique de communication avec Ollama.
 */

const express = require('express');
const cors = require('cors');
const path = require('path');

const app = express();
const PORT = 3001;
const OLLAMA_API_URL = 'http://localhost:11434';

// Middleware
app.use(cors()); // Autorise les requÃªtes cross-origin
app.use(express.json()); // Parse le JSON des requÃªtes
app.use(express.static(path.join(__dirname, '../frontend'))); // Sert les fichiers statiques

/**
 * Route pour lister les modÃ¨les disponibles sur Ollama
 * GET /api/models
 */
app.get('/api/models', async (req, res) => {
  try {
    const response = await fetch(`${OLLAMA_API_URL}/api/tags`);
    
    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.status}`);
    }
    
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error('Erreur lors de la rÃ©cupÃ©ration des modÃ¨les:', error);
    res.status(500).json({ 
      error: 'Impossible de rÃ©cupÃ©rer les modÃ¨les',
      details: error.message 
    });
  }
});

/**
 * Route pour envoyer un message au modÃ¨le Ollama
 * POST /api/chat
 * Body: { model: string, prompt: string }
 */
app.post('/api/chat', async (req, res) => {
  const { model, prompt } = req.body;
  
  // Validation des donnÃ©es
  if (!model || !prompt) {
    return res.status(400).json({ 
      error: 'Le modÃ¨le et le prompt sont requis' 
    });
  }
  
  try {
    const response = await fetch(`${OLLAMA_API_URL}/api/generate`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: model,
        prompt: prompt,
        stream: false // DÃ©sactive le streaming pour simplifier
      })
    });
    
    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.status}`);
    }
    
    const data = await response.json();
    res.json(data);
  } catch (error) {
    console.error('Erreur lors de la gÃ©nÃ©ration:', error);
    res.status(500).json({ 
      error: 'Erreur lors de la communication avec Ollama',
      details: error.message 
    });
  }
});

/**
 * Route de santÃ© pour vÃ©rifier si Ollama est accessible
 * GET /api/health
 */
app.get('/api/health', async (req, res) => {
  try {
    const response = await fetch(`${OLLAMA_API_URL}/api/tags`);
    
    if (response.ok) {
      res.json({ 
        status: 'ok', 
        ollama: 'connected',
        message: 'Ollama est accessible' 
      });
    } else {
      res.status(503).json({ 
        status: 'error', 
        ollama: 'disconnected',
        message: 'Ollama ne rÃ©pond pas correctement' 
      });
    }
  } catch (error) {
    res.status(503).json({ 
      status: 'error', 
      ollama: 'disconnected',
      message: 'Impossible de se connecter Ã  Ollama',
      details: error.message
    });
  }
});

// DÃ©marrage du serveur
app.listen(PORT, () => {
  console.log(`ğŸš€ Serveur dÃ©marrÃ© sur http://localhost:${PORT}`);
  console.log(`ğŸ“¡ Proxy Ollama configurÃ© sur ${OLLAMA_API_URL}`);
  console.log(`\nğŸ’¡ Assurez-vous qu'Ollama est lancÃ© avec: ollama serve`);
});