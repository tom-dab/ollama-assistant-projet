# Guide d'Installation et d'Utilisation

**Projet** : Ollama Web Interface  
**Auteur** : [Ton nom]  
**Date** : 13 janvier 2025

---

## ğŸ“‹ PrÃ©requis

Avant de commencer, assurez-vous d'avoir installÃ© :

- **Node.js** version 18 ou supÃ©rieure ([TÃ©lÃ©charger](https://nodejs.org/))
- **Ollama** ([TÃ©lÃ©charger](https://ollama.com/download))

### VÃ©rifier les installations

```bash
# VÃ©rifier Node.js
node --version
# Doit afficher v18.x.x ou supÃ©rieur

# VÃ©rifier npm
npm --version
# Doit afficher 9.x.x ou supÃ©rieur
```

---

## ğŸš€ Installation

### 1. TÃ©lÃ©charger le projet

Si vous avez reÃ§u une archive ZIP :
```bash
# DÃ©compresser l'archive
# Puis ouvrir un terminal dans le dossier dÃ©compressÃ©
```

Si c'est un repo Git :
```bash
git clone [URL_DU_REPO]
cd ollama-assistant-projet
```

### 2. Installer les dÃ©pendances

```bash
npm install
```

Cette commande va installer :
- Express (serveur web)
- CORS (gestion des requÃªtes cross-origin)
- Jest (tests unitaires)
- Supertest (tests API)

**â±ï¸ DurÃ©e** : ~30 secondes

---

## ğŸ¤– PrÃ©parer Ollama

### 1. Installer Ollama

Si ce n'est pas dÃ©jÃ  fait :

**Windows** :  
TÃ©lÃ©charger et installer depuis https://ollama.com/download

**macOS** :
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Linux** :
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 2. TÃ©lÃ©charger un modÃ¨le

```bash
# ModÃ¨le recommandÃ© pour le code (4.7 GB)
ollama pull qwen2.5-coder:7b
```

**â±ï¸ DurÃ©e** : ~5 minutes selon votre connexion

**Autres modÃ¨les disponibles** :
- `qwen2.5:0.5b` (397 MB) - TrÃ¨s lÃ©ger et rapide
- `qwen3-coder:latest` (18 GB) - Plus performant mais lourd
- `deepseek-coder:latest` (776 MB) - SpÃ©cialisÃ© code

### 3. Lancer Ollama en arriÃ¨re-plan

**Ouvrir un premier terminal** et taper :

```bash
ollama serve
```

Vous devriez voir :
```
Listening on 127.0.0.1:11434 (version 0.x.x)
```

âœ… **Laissez ce terminal ouvert !** Ollama doit tourner en permanence.

---

## â–¶ï¸ Lancer l'application

### 1. Ouvrir un second terminal

Dans le dossier du projet :

```bash
npm start
```

Vous devriez voir :
```
ğŸš€ Serveur dÃ©marrÃ© sur http://localhost:3001
ğŸ“¡ Proxy Ollama configurÃ© sur http://localhost:11434

ğŸ’¡ Assurez-vous qu'Ollama est lancÃ© avec: ollama serve
```

### 2. Ouvrir dans le navigateur

Aller sur : **http://localhost:3001**

---

## âœ… VÃ©rification du fonctionnement

Une fois l'application ouverte, vous devriez voir :

1. **En-tÃªte bleu** avec le titre "ğŸ¤– Ollama Assistant"

2. **Indicateur de statut vert** :
   ```
   ğŸŸ¢ ConnectÃ© Ã  Ollama
   ```

3. **Liste dÃ©roulante "ModÃ¨le"** avec vos modÃ¨les installÃ©s :
   ```
   qwen2.5-coder:7b (4.7 GB)
   ```

4. **Zone de chat** avec le message de bienvenue

5. **Champ de texte** et bouton "ğŸ“¤ Envoyer"

---

## ğŸ§ª Tester l'application

### 1. SÃ©lectionner un modÃ¨le

Cliquer sur la liste dÃ©roulante et choisir un modÃ¨le (ex: `qwen2.5-coder:7b`)

### 2. Poser une question

Exemples de questions Ã  tester :

```
Explique-moi ce qu'est une closure en JavaScript
```

```
Ã‰cris une fonction Python pour trier une liste par ordre dÃ©croissant
```

```
Comment fonctionne async/await en JavaScript ?
```

### 3. Observer la rÃ©ponse

- Un indicateur de chargement s'affiche (3 points animÃ©s)
- La rÃ©ponse apparaÃ®t aprÃ¨s quelques secondes
- Le code est formatÃ© avec coloration syntaxique

---

## ğŸ§ª Lancer les tests unitaires

Le projet inclut des tests automatisÃ©s.

```bash
# Lancer tous les tests
npm test

# Avec rapport de couverture
npm run test:coverage
```

**RÃ©sultat attendu** :
```
PASS  backend/server.test.js
PASS  frontend/script.test.js

Test Suites: 2 passed, 2 total
Tests:       25 passed, 25 total
Time:        3.456 s
```

---

## ğŸ›‘ ArrÃªter l'application

### Pour arrÃªter le serveur :
Dans le terminal du serveur, appuyer sur **Ctrl + C**

### Pour arrÃªter Ollama :
Dans le terminal d'Ollama, appuyer sur **Ctrl + C**

---

## âŒ RÃ©solution des problÃ¨mes

### ProblÃ¨me 1 : "Serveur non disponible" (point rouge)

**Cause** : Le serveur backend n'est pas lancÃ©

**Solution** :
```bash
npm start
```

---

### ProblÃ¨me 2 : "Ollama non disponible" (point rouge)

**Cause** : Ollama n'est pas lancÃ©

**Solution** :
```bash
# Dans un terminal sÃ©parÃ©
ollama serve
```

VÃ©rifier qu'il Ã©coute sur le port 11434.

---

### ProblÃ¨me 3 : "Aucun modÃ¨le trouvÃ©"

**Cause** : Aucun modÃ¨le Ollama installÃ©

**Solution** :
```bash
ollama pull qwen2.5-coder:7b
```

Puis rafraÃ®chir la page (F5).

---

### ProblÃ¨me 4 : Port 3001 dÃ©jÃ  utilisÃ©

**Erreur** :
```
Error: listen EADDRINUSE: address already in use :::3001
```

**Solution 1** : Trouver et tuer le processus
```bash
# Windows
netstat -ano | findstr :3001
taskkill /PID [NUMERO] /F

# macOS/Linux
lsof -ti:3001 | xargs kill -9
```

**Solution 2** : Changer le port dans `backend/server.js` (ligne 7)
```javascript
const PORT = 3002; // ou 4000, 5000, etc.
```

Puis aussi dans `frontend/script.js` (ligne 7) :
```javascript
const API_URL = 'http://localhost:3002/api';
```

---

### ProblÃ¨me 5 : npm install Ã©choue dans PowerShell

**Erreur** : Variable LASTEXITCODE non dÃ©finie

**Solution** : Utiliser CMD au lieu de PowerShell
```bash
# Ouvrir un terminal CMD
cmd

# Puis
npm install
```

---

## ğŸ“ Structure du projet

```
ollama-assistant-projet/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.js              # Serveur Express (API)
â”‚   â””â”€â”€ server.test.js         # Tests backend
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html             # Interface utilisateur
â”‚   â”œâ”€â”€ style.css              # Styles
â”‚   â”œâ”€â”€ script.js              # Logique frontend
â”‚   â””â”€â”€ script.test.js         # Tests frontend
â”œâ”€â”€ node_modules/              # DÃ©pendances (gÃ©nÃ©rÃ©)
â”œâ”€â”€ package.json               # Configuration npm
â”œâ”€â”€ README.md                  # Documentation principale
â”œâ”€â”€ TESTS.md                   # Documentation des tests
â”œâ”€â”€ ANALYSE_CRITIQUE.md        # Analyse du code
â”œâ”€â”€ GUIDE_INSTALLATION.md      # Ce fichier
â””â”€â”€ .gitignore                 # Fichiers ignorÃ©s par Git
```

---

## ğŸ”§ Configuration avancÃ©e (optionnel)

### Changer l'URL d'Ollama

Si Ollama tourne sur un autre port ou serveur :

**Fichier** : `backend/server.js` (ligne 8)
```javascript
const OLLAMA_API_URL = 'http://localhost:11434'; // Modifier ici
```

### Activer le mode dÃ©veloppement

Pour que le serveur redÃ©marre automatiquement Ã  chaque modification :

```bash
npm run dev
```

NÃ©cessite `nodemon` (dÃ©jÃ  dans les dÃ©pendances).

---

## ğŸ“ Support

Si vous rencontrez un problÃ¨me non listÃ© ici :

1. VÃ©rifier les logs dans les terminaux
2. VÃ©rifier que toutes les dÃ©pendances sont installÃ©es
3. Consulter le fichier `ANALYSE_CRITIQUE.md` pour les limitations connues

---

## ğŸ“ Checklist pour la premiÃ¨re utilisation

- [ ] Node.js installÃ© (v18+)
- [ ] Ollama installÃ©
- [ ] `npm install` exÃ©cutÃ©
- [ ] Au moins un modÃ¨le tÃ©lÃ©chargÃ© (`ollama pull qwen2.5-coder:7b`)
- [ ] Terminal 1 : `ollama serve` lancÃ©
- [ ] Terminal 2 : `npm start` lancÃ©
- [ ] Navigateur ouvert sur http://localhost:3001
- [ ] Indicateur vert "ConnectÃ© Ã  Ollama"
- [ ] ModÃ¨le sÃ©lectionnÃ© dans la liste
- [ ] Question posÃ©e et rÃ©ponse reÃ§ue

---

**Bon test ! ğŸš€**

---

**Contact** : [Ton email ou info de contact]